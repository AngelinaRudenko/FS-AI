\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{enumitem}
% \usepackage{pdfpages}

\setlength{\parskip}{0.9em}
\setlength{\parindent}{0pt}

\title{Artificial Intelligence -- Semester Project \\[0.5em]
\large Data Analysis and Application of a Selected Machine Learning Method}
\author{Anhelina Rudzenka rudzeanh@fel.cvut.cz}
\date{\today}

\begin{document}
\maketitle


% Google COllab link to the code:
% https://colab.research.google.com/drive/14Ko9NzpKZGfawO7YVp_15a5EEHjBnkYC?usp=sharing

% --------------------------------------------------------------------

\section{Introduction (0.5--1 page)}
\begin{itemize}[leftmargin=*]
    \item Brief introduction to the selected method and problem.
    \item Motivation for dataset choice and its relevance.
    \item Structure of the report.
\end{itemize}

% --------------------------------------------------------------------

\section{Dataset Description}

\textbf{Dataset Name:} Flight Price Prediction \\
\textbf{Source:} Kaggle \\
\textbf{URL:} \href{https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction/data}{Kaggle Dataset Link}

This dataset contains information about flight booking options from the website "Ease My Trip" for travel between India's top 6 metro cities.
The data shows different flight options with their prices, airlines, departure times, and other details.
Data was collected for 50 days, from February 11th to March 31st, 2022.

The original dataset includes 3 CSV files:

\begin{itemize}[leftmargin=*]
    \item \textbf{business.csv} -- 93487 business class flight records
    \item \textbf{economy.csv} -- 206774 economy class flight records
    \item \textbf{Clean\_Dataset.csv} -- 300153 flight records (combined and cleaned dataset)
\end{itemize}

For this project, I used the \textbf{Clean\_Dataset.csv} file because it combines both business and economy class flight records into a single dataset and has already been cleaned, with 108 invalid rows removed.

The dataset consists of approximately 69\% economy class flights and 31\% business class flights, indicating a moderate imbalance toward economy class bookings that reflects real-world travel patterns.

The dataset has 11 columns that describe each flight:

\begin{itemize}[leftmargin=*]
    
    \item \textbf{airline} -- Airline company name 
    (6 airlines: SpiceJet, AirAsia, Vistara, GO\_FIRST, Indigo, Air\_India).

    \item \textbf{flight} -- Flight code or flight number  
    (1561 unique flight codes).

    \item \textbf{source\_city} -- Departure city  
    (6 cities: Delhi, Mumbai, Bangalore, Kolkata, Hyderabad, Chennai).

    \item \textbf{departure\_time} -- Time of day when the flight departs  
    (6 time periods: Early\_Morning, Morning, Afternoon, Evening, Night, Late\_Night).

    \item \textbf{stops} -- Number of stops during the flight  
    (3 categories: zero, one, two\_or\_more).

    \item \textbf{arrival\_time} -- Time of day when the flight arrives  
    (Same six time periods as the departure time).

    \item \textbf{destination\_city} -- City where the flight arrives  
    (Same six cities as the source city).

    \item \textbf{class} -- Type of ticket  
    (2 classes: economy, business).

    \item \textbf{duration} -- Total flight duration in hours  
    (Range: 0.83 to 49.83 hours, with 476 distinct values).

    \item \textbf{days\_left} -- Number of days remaining until departure  
    (Range: 1 to 49 days).

    \item \textbf{price} -- Flight ticket price in Indian Rupees (INR).

\end{itemize}

There are three numerical features (\texttt{duration}, \texttt{days\_left}, \texttt{price}), while all other features are categorical text data.

During the exploratory analysis, I found the following key points:

\begin{itemize}
    \item The mean ticket price is 20889.66, while the median price is 7425.00. This shows that the price distribution is highly skewed, with some very expensive tickets that increase the average price.
    \item Most passengers travel in the economy class.
    \item Most flights have one stop.
    \item There are very few late-night flights.
\end{itemize}

During the identification of dataset issues, I found the following:

\begin{itemize}
    \item The dataset is fully complete, with no missing values in any of the columns.
    \item The data do not contain significant outliers. Less than 1\% of the observations are outliers.
    \item None of the numerical features (\texttt{duration}, \texttt{days\_left}, \texttt{price}) are highly correlated with each other.
    \item There is a strong class imbalance in the \texttt{flight} and \texttt{departure\_time} columns. The imbalance ratios are approximately 54.48:1 for \texttt{departure\_time} and 3235:1 for \texttt{flight}.
    \item For the \texttt{departure\_time} column, morning flights account for 24\% of the data, while late-night flights represent only 0.4\%. This suggests that people tend to avoid late flights.
    \item For the \texttt{flight} column, this likely means that some flights operate much more often than others.
\end{itemize}

The plots used for the exploratory analysis and dataset issues identification are provided in the appendix.
I also generated a data profile using \texttt{ydata-profiling}, which is also included in the appendix.

% --------------------------------------------------------------------

\section{Problem Definition}

The problem can be formulated as follows: given information about a flight, we want to predict the ticket price in Indian Rupees (INR).

This is a supervised learning problem, because the dataset contains labeled data (flights with known prices). More specifically, this is a regression task, because we predict the price, which is a continuous numerical value.

For this project, I chose to use Random Forest Regression as the main prediction algorithm. 
Random Forest Regression builds many decision trees and combines their predictions to make a strong model.
This choice is justified by several reasons.

First, works well with both numerical and categorical features, which matches the dataset.

Second, Random Forest can capture non-linear relationships. The relationship between features and price is not always linear.

Fourth, Random Forest handles feature interactions automatically. The price may depend on combinations of features, and the model discovers these interactions during training without manual specification.

Finally, the model is less prone to overfitting compared to a single decision tree.

% --------------------------------------------------------------------

\section{Data Preprocessing}

During the exploratory data analysis in the previous chapter, I checked the dataset for common problems. Here, I describe the issues found and how they were addressed.

\textbf{Outliers}\\
\textit{Issue:} Some flights had unusually long durations or very high prices.\\
\textit{Action:} I kept all outliers in the dataset. This is because Random Forest models handle outliers well, and these extreme values represent real scenarios, such as multi-stop journeys or business class tickets peak times. Removing them could discard useful information about expensive flight options.

\textbf{Irrelevant Features}\\
\textit{Issue:} The \texttt{Unnamed: 0} column was only an index. The \texttt{flight} column contained flight codes, which had too many unique values and mostly reflected historical data, not useful for learning general price patterns.\\
\textit{Action:} Both columns were removed. This reduced noise and made the data simpler for the model.

I applied the following preprocessing steps:

\begin{enumerate}
    \item \textbf{Feature Selection:} The \texttt{Unnamed: 0} and \texttt{flight} columns were removed as they were irrelevant.
    
    \item \textbf{Separating Features and Target Variable:} The dataset was split into features ($X$) and the target variable ($y$). The target variable was the \texttt{price} column, while $X$ contained all other columns used for prediction.
    
    \item \textbf{Encoding Categorical Data:} All categorical features were converted from text labels to numbers using label encoding. Machine learning algorithms, including Random Forest, require numerical input.
    
    \item \textbf{Train-Test Split:} The dataset was divided into training and testing sets. The training set contained 80\% of the data for model learning, and the test set contained 20\% to evaluate model performance on unseen data.
\end{enumerate}

Each preprocessing step was chosen to ensure that the data would be suitable for Random Forest regression, which works best with clean, relevant, and numerical data.

% --------------------------------------------------------------------

\section{Machine Learning Method}

Random Forest is an ensemble learning method that combines multiple decision trees to make predictions. Instead of relying on a single decision tree, it builds many trees and averages their results to get a final prediction.

The algorithm creates multiple random subsets of the training data. Each subset is created by randomly selecting samples with replacement (some samples can appear multiple times, others not at all).

For each data subset, a decision tree is built. However, when splitting nodes in the tree, only a random subset of features is considered at each split point. This makes the trees different from each other.

When we want to predict a value for new data, all trees make their own predictions. The final prediction is the average of all tree predictions.

Mathematically, if we have $N$ decision trees in the forest, and each tree $i$ makes a prediction $\hat{y}_i(x)$ for an input $x$, the final prediction $\hat{y}(x)$ is given by:

\[
\hat{y}(x) = \frac{1}{N} \sum_{i=1}^{N} \hat{y}_i(x)
\]

This averaging helps to reduce overfitting and improves generalization compared to a single decision tree.

Random Forest Regression has several important parameters that control how the model is built:

\begin{description}
    \item[\texttt{n\_estimators}] 
    This parameter defines the number of trees in the forest. A larger number usually improves performance, but it also increases training time. In practice, values between 100 and 300 are often used.

    \item[\texttt{max\_depth}] 
    This parameter sets the maximum depth of each tree. Limiting the depth can prevent overfitting. However, if set too low, it may lead to underfitting.

    \item[\texttt{min\_samples\_split}] 
    This is the minimum number of samples required to split an internal node. Higher values prevent the tree from learning too specific patterns.

    \item[\texttt{min\_samples\_leaf}] 
    This parameter defines the minimum number of samples in a leaf node. It helps to smooth the predictions and reduce noise.

    \item[\texttt{max\_features}] 
    This defines how many features are randomly selected at each split.

    \item[\texttt{random\_state}] 
    This parameter is used to make the results reproducible. Setting it to a fixed number ensures that the same random choices are made each time the model is trained.
\end{description}

Random Forest structure is defined by a collection of independent decision trees. Each tree has a hierarchical structure with internal decision nodes and leaf nodes that store prediction values.

% --------------------------------------------------------------------

\section{Experiments and Results}

First, I created a baseline model to see how well Random Forest works with simple settings. The baseline model used the parameters shown in Table~\ref{tab:rf_baseline}.

\begin{table}[h]
\centering
\caption{Random Forest Baseline Model Parameters}
\label{tab:rf_baseline}
\begin{tabular}{lll}
\hline
\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\
\hline
\texttt{n\_estimators} & 100 & Number of decision trees \\
\texttt{max\_depth} & None & Maximum depth of the trees \\
\texttt{min\_samples\_split} & 2 & Minimum samples required to split a node \\
\texttt{min\_samples\_leaf} & 1 & Minimum samples allowed in a leaf node \\
\texttt{max\_features} & \texttt{sqrt} & Number of features considered at each split \\
\texttt{random\_state} & 42 & Ensures reproducible results \\
\texttt{n\_jobs} & -1 & Uses all available CPU cores \\
\hline
\end{tabular}
\end{table}

The baseline model achieved strong performance on the test dataset:
\begin{itemize}
    \item \textbf{Test $R^2$:} 0.9841 (98.41\%)
    \item \textbf{Test MAE:} 1221.10 INR
    \item \textbf{Test RMSE:} 2859.63 INR
\end{itemize}

These results were already very good, but I wanted to see if I could improve them.
I manually adjusted the model parameters to try to improve performance. The final tuned model used the parameters shown in Table~\ref{tab:rf_tuned}.

\begin{table}[h]
\centering
\caption{Random Forest Tuned Model Parameters}
\label{tab:rf_tuned}
\begin{tabular}{llll}
\hline
\textbf{Parameter} & \textbf{Baseline} & \textbf{Tuned} & \textbf{Why I changed it} \\
\hline
\texttt{n\_estimators} & 100 & 200 & More trees can make better predictions \\
\texttt{max\_depth} & None & None & Kept unlimited (worked well) \\
\texttt{min\_samples\_split} & 2 & 5 & Prevent trees from splitting too easily \\
\texttt{min\_samples\_leaf} & 1 & 2 & Make predictions smoother \\
\texttt{max\_features} & \texttt{'sqrt'} & 0.5 & Use 50\% of features for more variety \\
\hline
\end{tabular}
\end{table}

I manually tested different parameters and compared the results. Then I compared the baseline and tuned models on the testing set, as shown in Table~\ref{tab:model_comparison}.

\begin{table}[h]
\centering
\caption{Comparison of Baseline and Tuned Models on the Testing Set}
\label{tab:model_comparison}
\begin{tabular}{llll}
\hline
\textbf{Metric} & \textbf{Baseline} & \textbf{Tuned} & \textbf{Improvement} \\
\hline
$R^2$ & 0.9841 & 0.9856 & +0.0014 \\
Adjusted $R^2$ & 0.9841 & 0.9856 & +0.0014 \\
MAE (INR) & 1221.10 & 1201.68 & --19.42 \\
RMSE (INR) & 2859.63 & 2727.88 & --131.75 \\
\hline
\end{tabular}
\end{table}

The tuned model is better on all four metrics, and therefore it was selected as the final model.

\textbf{Important note:} The training scores for the tuned model appear worse than those of the baseline model, which may seem suspicious. However, the testing performance is the key evaluation criterion. Since the testing scores improved, the tuned model generalizes better to unseen data, which is the primary objective.

I used five different metrics to measure how well the model works:

\textbf{$R^2$ (R-squared)} \\
\textbf{Final value:} 0.9856 (98.56\%) \\
\textbf{What it means:} The model explains 98.56\% of the differences in flight prices. \\
\textbf{Interpretation:} Good result. Anything above 90\% is considered very good.

\textbf{Adjusted $R^2$} \\
\textbf{Final value:} 0.9856 (98.56\%) \\
\textbf{What it means:} Same as $R^2$, but adjusted for the number of features. \\
\textbf{Interpretation:} The value is the same as $R^2$, which confirms the model is truly good and not just inflated by having many features.

\textbf{MAE (Mean Absolute Error)} \\
\textbf{Final value:} INR 1201.68 \\
\textbf{What it means:} On average, predictions are off by INR 1201.68. \\
\textbf{Interpretation:} The average flight price is INR 20894, so an error of INR 1201.68 is 5.75\% of the average price. This is acceptable for price prediction.

\textbf{RMSE (Root Mean Squared Error)} \\
\textbf{Final value:} INR 2727.88 \\
\textbf{What it means:} Similar to MAE, but gives more weight to large errors. \\
\textbf{Interpretation:} This value is higher than MAE because it penalizes large mistakes more strongly. It indicates that some predictions are further off, but overall the model remains reliable.

\textbf{MSE (Mean Squared Error)} \\
\textbf{Final value:} INR 7441302.56 \\
\textbf{What it means:} Average of squared errors. \\
\textbf{Interpretation:} This metric is difficult to interpret directly because it is expressed in squared rupees. However, lower values indicate better performance. The RMSE, which is the square root of the MSE, is easier to interpret.

After training the model, I also checked which features are most important for predicting flight prices. The resulting feature importance ranking is shown in Table~\ref{tab:feature_importance}.

\begin{table}[h]
\centering
\caption{Feature Importance for Flight Price Prediction}
\label{tab:feature_importance}
\begin{tabular}{llll}
\hline
\textbf{Rank} & \textbf{Feature} & \textbf{Importance} & \textbf{Percentage} \\
\hline
1 & class & 0.8238 & 82.38\% \\
2 & airline & 0.0631 & 6.31\% \\
3 & duration & 0.0514 & 5.14\% \\
4 & stops & 0.0171 & 1.71\% \\
5 & days\_left & 0.0166 & 1.66\% \\
6 & source\_city & 0.0097 & 0.97\% \\
7 & destination\_city & 0.0096 & 0.96\% \\
8 & arrival\_time & 0.0047 & 0.47\% \\
9 & departure\_time & 0.0040 & 0.40\% \\
\hline
\end{tabular}
\end{table}

\textbf{Key findings:}
\begin{itemize}
    \item \textbf{Class} is by far the most important feature (82\%), which is expected since business class tickets are significantly more expensive than economy tickets.
    \item \textbf{Airline} plays a notable role (6\%), as different airlines apply different pricing strategies.
    \item \textbf{Duration} has a meaningful impact (5\%), with longer flights generally costing more.
    \item \textbf{Departure time} and \textbf{arrival time} have minimal influence (less than 1\%) on ticket prices in this dataset.
\end{itemize}

This ranking helps to identify the primary factors driving flight prices in the Indian market.

% Instead of ROC (ised for classification), I did residual plot

The plot comparing actual and predicted flight prices is provided in Appendix~\ref{app:plots} (Figure~\ref{fig:actual_vs_predicted}).

\textbf{What this plot shows:}
\begin{itemize}
    \item Each dot represents one flight
    \item X-axis: actual price of the flight
    \item Y-axis: price predicted by the model
    \item Red dashed line: perfect predictions (predicted price equals actual price)
\end{itemize}

\textbf{Interpretation:}  
Most points lie close to the red dashed line, indicating that the predictions are accurate. The points form a tight cluster around the diagonal, showing that the model successfully learned the underlying patterns in the data. There are some points that spread out (especially for expensive flights), but overall the fit is good.

The distribution of prediction errors is shown in Appendix~\ref{app:plots} (Figure~\ref{fig:error_distribution}).

\textbf{What this plot shows:}
\begin{itemize}
    \item How often the model makes different sized errors
    \item X-axis: prediction error (actual price minus predicted price)
    \item Y-axis: number of flights with a given error
    \item Green line: average error (approximately zero)
\end{itemize}

\textbf{Interpretation:}  
The histogram has a distribution centered around zero, which is the desired outcome. Most predictions have very small errors, as shown by the high bar near zero. Errors are balanced on both sides, indicating that the model does not systematically over-predict or under-predict.

The residual plot is included in Appendix~\ref{app:plots} (Figure~\ref{fig:residual_plot}).

\textbf{What this plot shows:}
\begin{itemize}
    \item Residuals (differences between actual and predicted prices)
    \item X-axis: predicted price
    \item Y-axis: residual (error)
    \item Red line: zero error
    \item Orange dotted lines: $\pm 1$ standard deviation ($\pm$INR 2728)
\end{itemize}

\textbf{Interpretation:}  
The plot shows mostly random scatter around the zero line, which is good. Some diagonal striping is visible. This is normal for Random Forest models because they make predictions by combining many trees, which creates discrete levels in the predictions. Errors are slightly larger for expensive flights. This is normal for price data because expensive flights naturally have more variation.

% --------------------------------------------------------------------

\section{Discussion (1 page)}
\begin{itemize}[leftmargin=*]
    \item Evaluation of strengths and weaknesses.
    \item What worked well and what did not, and why.
    \item Possible alternatives and future improvements.
\end{itemize}

% --------------------------------------------------------------------

\section{Conclusion (0.5--1 page)}
\begin{itemize}[leftmargin=*]
    \item Summary of approach and key findings.
    \item Whether the objective was met and why.
    \item Short summary of lessons learned.
\end{itemize}

% --------------------------------------------------------------------

\section*{Appendices}

\section*{Appendix: Dataset Description Plots}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/exploratory-analysis-price-distribution-histogram.png}
    \caption{Price distribution of airline tickets.}
    \label{fig:price_distribution}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/numerical-features-distribution.png}
    \caption{Other numerical attributes distribution.}
    \label{fig:numerical-features-distribution}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/categorical-features-distribution.png}
    \caption{Categorical attributes distribution.}
    \label{fig:categorical-features-distribution}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/correlation-matrix.png}
    \caption{Correlation matrix.}
    \label{fig:correlation-matrix}
\end{figure}

\section*{Appendix: Data Profile}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report01.png}
    \caption{Data Profile Report - part 1.}
    \label{fig:data-profile-report1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report02.png}
    \caption{Data Profile Report - part 2.}
    \label{fig:data-profile-report2}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report03.png}
    \caption{Data Profile Report - part 3.}
    \label{fig:data-profile-report3}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report04.png}
    \caption{Data Profile Report - part 4.}
    \label{fig:data-profile-report4}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report05.png}
    \caption{Data Profile Report - part 5.}
    \label{fig:data-profile-report5}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report06.png}
    \caption{Data Profile Report - part 6.}
    \label{fig:data-profile-report6}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report07.png}
    \caption{Data Profile Report - part 7.}
    \label{fig:data-profile-report7}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{figures/data-profile-report08.png}
    \caption{Data Profile Report - part 8.}
    \label{fig:data-profile-report8}
\end{figure}


\section*{Appendix: Plots}
\label{app:plots}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/PlotActualVsPredictedPrices.png}
    \caption{Actual vs Predicted Flight Prices}
    \label{fig:actual_vs_predicted}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/PlotDistributionOfPredictionErrors.png}
    \caption{Distribution of Prediction Errors}
    \label{fig:error_distribution}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/PlotResidual.png}
    \caption{Residual Plot}
    \label{fig:residual_plot}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/PlotLearningCurves.png}
    \caption{Learning Curves}
    \label{fig:learning_curve}
\end{figure}


\section*{Declaration of Generative AI Usage}

As part of this semester project, I used generative AI tools (GitHub Copilot) for the following purposes: \
\begin{itemize}
    \item consulting theoretical explanations and verifying correctness,
    \item drafting or reviewing parts of the code,
    \item language proofreading of the text.
\end{itemize}
I fully understand all methods, code, and interpretations used in this work and can independently explain them during the oral exam. I acknowledge that I bear full responsibility for the correctness of all content, calculations, code, and conclusions presented in this project.

\end{document}